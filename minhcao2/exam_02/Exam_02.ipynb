{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics 207  Exam 2\n",
    "---\n",
    "\n",
    "## Name: Michael Cao\n",
    "---\n",
    "\n",
    "## Net ID: minhcao2\n",
    "---\n",
    "\n",
    "#### Release Date: Monday, April 13, 2020\n",
    "\n",
    "#### Due Date: Committed and pushed before 11:59pm  Tuesday, April 14, 2020\n",
    "\n",
    "Scoring: Each Problem section is worth 5 points, for a total of 100 points on the exam.\n",
    "\n",
    "Do all your work in this notebook. Show your work unless directed only to provide the answer. This is an open notes exam. You must work independently  with no assistance from anyone else.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### Grader Scoring\n",
    "\n",
    "Problem | Number of parts | Points possible | Your Score\n",
    "--- | --- | --- | ---\n",
    "1 | 4 | 20 | $\\qquad$\n",
    "2 | 4 | 20 | $\\qquad$\n",
    "3 | 4 | 20 | $\\qquad$\n",
    "4 | 4 | 20 | $\\qquad$\n",
    "5 | 4 | 20 | $\\qquad$\n",
    "Total | 20 | 100 | $\\qquad\\qquad$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Problem 1.** \n",
    "\n",
    "A polling organization conducted a statewide survey concerning the race for governor. In a random phone number survey, 400 registered voters responded. It was found that 230 would vote for the Democratic candidate. Let p represent the proportion of registered voters in the state that would vote for the Democratic candidate. Assume the sample of respondents is equivalent to a random sample from the population of registered voters in the state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** Calculate an estimate for $p$ based on the poll results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.575"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 230/400\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Calculate the standard error for the estimate of $p$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.024717149916606486"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SE = np.sqrt((p * (1 - p)) / 400)\n",
    "SE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** We wish to test the null hypothesis $H_0: p=0.5$ against the alternative $H_A: p\\ne 0.5$. Based on the poll results, calculate the p-value of a large sample z-test of $H_0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.0343304245450398, 0.0024107023750756795)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = (0.575 - 0.5)/ SE\n",
    "z\n",
    "p_value = 2*(1 - norm.cdf(z))\n",
    "z, p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)** The odds of an event is the ratio of the probability that the event occurs to the probability of that the event does not occur. Using your results above, compute an estimate of the odds that a randomly chosen registered voter would vote for the Democrative candidate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.352941176470588"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odd = p / (1 - p)\n",
    "odd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Problem 2.** \n",
    "\n",
    "Data were collected from 39 students in a university class. The variables were:\n",
    "\n",
    "+ happy: Happiness on a 10 point scale, where 10 is most happy\n",
    "\n",
    "+ money: family income in thousands of dollars\n",
    "\n",
    "+ sex: 1 = satisfactory sexual activity, 0 = not\n",
    "\n",
    "+ love: 1 = lonely, 2 = secure relationships, 3 = deep feeling of belonging and caring\n",
    "\n",
    "+ work: 5 point scale where 1 = no job, 3 = OK job, 5 = great job\n",
    "\n",
    "The data are in the included file 'happy.csv'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** We read the data into a data frame and display the correlation matrix of all the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>happy</th>\n",
       "      <th>money</th>\n",
       "      <th>sex</th>\n",
       "      <th>love</th>\n",
       "      <th>work</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>happy</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.270942</td>\n",
       "      <td>-0.032590</td>\n",
       "      <td>0.784219</td>\n",
       "      <td>0.539170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>money</th>\n",
       "      <td>0.270942</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.306506</td>\n",
       "      <td>0.125815</td>\n",
       "      <td>0.067748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>-0.032590</td>\n",
       "      <td>0.306506</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.047160</td>\n",
       "      <td>-0.316343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>0.784219</td>\n",
       "      <td>0.125815</td>\n",
       "      <td>0.047160</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.385696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work</th>\n",
       "      <td>0.539170</td>\n",
       "      <td>0.067748</td>\n",
       "      <td>-0.316343</td>\n",
       "      <td>0.385696</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          happy     money       sex      love      work\n",
       "happy  1.000000  0.270942 -0.032590  0.784219  0.539170\n",
       "money  0.270942  1.000000  0.306506  0.125815  0.067748\n",
       "sex   -0.032590  0.306506  1.000000  0.047160 -0.316343\n",
       "love   0.784219  0.125815  0.047160  1.000000  0.385696\n",
       "work   0.539170  0.067748 -0.316343  0.385696  1.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep\n",
    "import pandas as pd\n",
    "df2 = pd.read_csv('happy.csv')\n",
    "df2.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in which of the variables are correlated with happiness, either positively or negatively. Which of the other variables have a sample correlation with 'happy' that is larger than 0.50 in absolute value? List all that do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "love, work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Below we fit a linear regression model with 'happy' as the response variable and 'money', 'sex', 'love and 'work' as explanatory variables. Display the model summary including at least the R-square value, the F-statistic for the model, the model coefficient estimates, and the coefficient standard errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "model1 = smf.ols('happy ~ money + sex + love + work', data=df2).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>happy</td>      <th>  R-squared:         </th> <td>   0.710</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.676</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   20.83</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 13 Apr 2020</td> <th>  Prob (F-statistic):</th> <td>9.36e-09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:06:52</td>     <th>  Log-Likelihood:    </th> <td> -54.877</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    39</td>      <th>  AIC:               </th> <td>   119.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    34</td>      <th>  BIC:               </th> <td>   128.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -0.0721</td> <td>    0.853</td> <td>   -0.085</td> <td> 0.933</td> <td>   -1.805</td> <td>    1.660</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>money</th>     <td>    0.0096</td> <td>    0.005</td> <td>    1.837</td> <td> 0.075</td> <td>   -0.001</td> <td>    0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sex</th>       <td>   -0.1490</td> <td>    0.419</td> <td>   -0.356</td> <td> 0.724</td> <td>   -1.000</td> <td>    0.702</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>love</th>      <td>    1.9193</td> <td>    0.295</td> <td>    6.496</td> <td> 0.000</td> <td>    1.319</td> <td>    2.520</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>work</th>      <td>    0.4761</td> <td>    0.199</td> <td>    2.388</td> <td> 0.023</td> <td>    0.071</td> <td>    0.881</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.561</td> <th>  Durbin-Watson:     </th> <td>   1.541</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.755</td> <th>  Jarque-Bera (JB):  </th> <td>   0.170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.155</td> <th>  Prob(JB):          </th> <td>   0.918</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.093</td> <th>  Cond. No.          </th> <td>    373.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  happy   R-squared:                       0.710\n",
       "Model:                            OLS   Adj. R-squared:                  0.676\n",
       "Method:                 Least Squares   F-statistic:                     20.83\n",
       "Date:                Mon, 13 Apr 2020   Prob (F-statistic):           9.36e-09\n",
       "Time:                        11:06:52   Log-Likelihood:                -54.877\n",
       "No. Observations:                  39   AIC:                             119.8\n",
       "Df Residuals:                      34   BIC:                             128.1\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -0.0721      0.853     -0.085      0.933      -1.805       1.660\n",
       "money          0.0096      0.005      1.837      0.075      -0.001       0.020\n",
       "sex           -0.1490      0.419     -0.356      0.724      -1.000       0.702\n",
       "love           1.9193      0.295      6.496      0.000       1.319       2.520\n",
       "work           0.4761      0.199      2.388      0.023       0.071       0.881\n",
       "==============================================================================\n",
       "Omnibus:                        0.561   Durbin-Watson:                   1.541\n",
       "Prob(Omnibus):                  0.755   Jarque-Bera (JB):                0.170\n",
       "Skew:                          -0.155   Prob(JB):                        0.918\n",
       "Kurtosis:                       3.093   Cond. No.                         373.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** List all of the explanatory variables whose coefficients estimates are significantly different than zero at an alpha significance level of 0.05."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Love and Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)** The regression model has the form:\n",
    "\n",
    "$$ \n",
    "E(\\text{happy}) = b_0 + b_1 * \\text{money} + b_2 * \\text{sex} + b_3 * \\text{love} + b_4 * \\text{work}.\n",
    "$$\n",
    "\n",
    "We perform the following F test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f</th>\n",
       "      <th>pvalue</th>\n",
       "      <th>df_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.725173</td>\n",
       "      <td>0.193371</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          f    pvalue  df_diff\n",
       "0  1.725173  0.193371      2.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep\n",
    "model1 = smf.ols('happy ~ money + sex + love + work', data=df2).fit()\n",
    "model0 = smf.ols('happy ~ love + work', data=df2).fit()\n",
    "f, p, df = model1.compare_f_test(model0)\n",
    "pd.DataFrame({'f': [f], 'pvalue': [p], 'df_diff': [df]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "State the null hypothesis for this F test in terms of the population model coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H_0$: $B_1$ = $B_2$ = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Problem 3.** \n",
    "\n",
    "The drug AZT was developed to try to delay the onset of AIDS in HIV positive patients. In a randomized double-blind study 950 HIV positive volunteers without AIDS were assigned to receive either AZT or placebo. At the end of the study the results were as follows.\n",
    "\n",
    "| $\\quad$ | No Aids | Aids |\n",
    "|---|---|---|\n",
    "| AZT | 413 | 12 |\n",
    "| Placebo | 392 | 33 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** For patients on AZT, calculate the estimated odds of developing AIDS over a time period of the same length as in the study. Do the same for patients on Placebo. Display and label the two odds estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.02823529411764706, 0.07764705882352942)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_of_aids_with_AZT = 12 / (12 + 413)\n",
    "p_of_aids_without_AZT = 33 / (33 + 392)\n",
    "p_of_aids_with_AZT, p_of_aids_without_AZT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.029055690072639227, 0.08418367346938777)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odd_of_aids_with_AZT = p_of_aids_with_AZT / (1 - p_of_aids_with_AZT)\n",
    "odd_of_aids_without_AZT = p_of_aids_without_AZT / (1 - p_of_aids_without_AZT)\n",
    "odd_of_aids_with_AZT, odd_of_aids_without_AZT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Calculate an odds ratio estimate to compare the effectiveness of AZT to Placebo in delaying the onset of AIDS. Based on your odds ratio, which treatment appears more effective and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.897321428571429"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odd_of_aids_without_AZT / odd_of_aids_with_AZT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8973214285714284"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odd_ratio = (413/392) / (12/33)\n",
    "odd_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treatment with AZT is more effective because the odd ratio is > 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Calculate the natural logarithm of the odds ratio you computed in b), and compute the standard error of the log-odds-ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0637866648490502"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_odd_ratio = np.log(odd_ratio)\n",
    "log_odd_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3443961259227231"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SE_log_odd_ratio = np.sqrt(1/413 + 1/392 + 1/12 + 1/33)\n",
    "SE_log_odd_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)** Under the null hypothesis that there is no difference in effectiveness between AZT and Placebo, what is the hypothesized value of the population log-odds-ratio? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.412758479233126"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = odd_ratio/SE_log_odd_ratio\n",
    "z\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can conclude that the AZT drug is effective because log-odds-ratio is not 0, also, z value for odd ratio is very high : 8.412, hence, we can reject null hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Problem 4.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data were collected from 39 students in a university class. Some of the variables were:\n",
    "\n",
    "+ happy: Happiness on a 10 point scale, where 10 is most happy\n",
    "\n",
    "+ money: family income in thousands of dollars\n",
    "\n",
    "+ sex: 1 = satisfactory sexual activity, 0 = not\n",
    "\n",
    "+ love: 1 = lonely, 2 = secure relationships, 3 = deep feeling of belonging and caring\n",
    "\n",
    "+ work: 5 point scale where 1 = no job, 3 = OK job, 5 = great job\n",
    "\n",
    "The data are in the included file 'happy.csv'.\n",
    "\n",
    "Consider the following Python code and results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.540229\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                    sex   No. Observations:                   39\n",
      "Model:                          Logit   Df Residuals:                       36\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Mon, 13 Apr 2020   Pseudo R-squ.:                  0.1248\n",
      "Time:                        11:42:10   Log-Likelihood:                -21.069\n",
      "converged:                       True   LL-Null:                       -24.072\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.04961\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      2.5938      1.899      1.366      0.172      -1.128       6.315\n",
      "love           0.8519      0.692      1.231      0.218      -0.504       2.208\n",
      "work          -1.0997      0.515     -2.135      0.033      -2.109      -0.090\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# keep\n",
    "df4 = pd.read_csv(\"happy.csv\")\n",
    "logit1 = smf.logit('sex ~ love + work', data=df4).fit()\n",
    "print(logit1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** For the individual with the record shown below, find the predicted probability for 'sex'=1 based on the fitted model.\n",
    "\n",
    "        happy     6\n",
    "        money    45\n",
    "        sex       0\n",
    "        love      2\n",
    "        work      3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9985000000000004"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = 2.5938 + 0.8519*2 - 1.0997*3\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Which, if any, of the explanatory variables has a coefficient that is significantly different from zero at an alpha level of 0.05?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Below is the confusion matrix if the model 'logit1' is used as a predictive classifier: we predict 'sex=1' for fitted probabilities $\\ge 0.50$, and we predict 'sex=0' for fitted probabilities $\\lt 0.50$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual 0</th>\n",
       "      <th>Actual 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Model Classified as 0</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model Classified as 1</th>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Actual 0  Actual 1\n",
       "Model Classified as 0         6         4\n",
       "Model Classified as 1         6        23"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score\n",
    "yhat = 1*(logit1.fittedvalues >= 0.50)\n",
    "tn, fp, fn, tp = confusion_matrix(y_true=df4['sex'], y_pred=yhat).ravel()\n",
    "pd.DataFrame({'Actual 0': [tn, fp], \n",
    "              'Actual 1': [fn, tp] }, \n",
    "             index=['Model Classified as 0', 'Model Classified as 1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the sensitivity of the classifier is the probability of classifying as 1 given that the true value is 1, what is the estimated sensitivity implied by the confusion matrix shown here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8518518518518519"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "23/(23+4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)** If the specificity of a classifier is the probability of classifying as 0 given that the true value is zero, find the estimated specificity of the classifer based on the model 'logit1'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept    2.593792\n",
       "love         0.851946\n",
       "work        -1.099733\n",
       "dtype: float64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit1.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def senspec(y, score, thresh):\n",
    "    yhat = 1*(score >= thresh)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true=y, y_pred=yhat).ravel()\n",
    "    sens = tp / (fn + tp)\n",
    "    spec = tn / (fp + tn)\n",
    "    return pd.DataFrame({'tn':[tn], \n",
    "                         'fp':[fp], \n",
    "                         'fn':[fn], \n",
    "                         'tp':[tp], \n",
    "                         'sens':[sens], \n",
    "                         'spec':[spec]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.679330\n",
       "1    0.982874\n",
       "2    0.413616\n",
       "3    0.864177\n",
       "4    0.776654\n",
       "5    0.679330\n",
       "6    0.679330\n",
       "7    0.730760\n",
       "8    0.890730\n",
       "9    0.278243\n",
       "dtype: float64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phat = logit1.predict(exog=df4[['work', 'love']])\n",
    "phat.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>sens</th>\n",
       "      <th>spec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tn  fp  fn  tp      sens  spec\n",
       "0   6   6   4  23  0.851852   0.5"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senspec(df4['sex'], phat, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speci = 6 / 12 \n",
    "speci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Problem 5.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data were collected on a sample of iris flowers of three different species. The data are in the file 'iris.csv'. The data are read in below and the variable names are displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species'], dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep\n",
    "df5 = pd.read_csv('iris.csv')\n",
    "df5.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SepalLength  SepalWidth  PetalLength  PetalWidth    Species\n",
       "0            5.1         3.5          1.4         0.2     setosa\n",
       "1            4.9         3.0          1.4         0.2     setosa\n",
       "2            4.7         3.2          1.3         0.2     setosa\n",
       "3            4.6         3.1          1.5         0.2     setosa\n",
       "4            5.0         3.6          1.4         0.2     setosa\n",
       "..           ...         ...          ...         ...        ...\n",
       "145          6.7         3.0          5.2         2.3  virginica\n",
       "146          6.3         2.5          5.0         1.9  virginica\n",
       "147          6.5         3.0          5.2         2.0  virginica\n",
       "148          6.2         3.4          5.4         2.3  virginica\n",
       "149          5.9         3.0          5.1         1.8  virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** Using the pandas groupby function, or otherwise, compute the sample means of 'PetalLength' for each of the three species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Species</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>setosa</th>\n",
       "      <td>5.006</td>\n",
       "      <td>3.428</td>\n",
       "      <td>1.462</td>\n",
       "      <td>0.246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>versicolor</th>\n",
       "      <td>5.936</td>\n",
       "      <td>2.770</td>\n",
       "      <td>4.260</td>\n",
       "      <td>1.326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>virginica</th>\n",
       "      <td>6.588</td>\n",
       "      <td>2.974</td>\n",
       "      <td>5.552</td>\n",
       "      <td>2.026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            SepalLength  SepalWidth  PetalLength  PetalWidth\n",
       "Species                                                     \n",
       "setosa            5.006       3.428        1.462       0.246\n",
       "versicolor        5.936       2.770        4.260       1.326\n",
       "virginica         6.588       2.974        5.552       2.026"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dfnew = df5.groupby(\"Species\").mean()\n",
    "dfnew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Fit a oneway anova regression model with 'PetalLength' as the response and 'Species' as the categorical explanatory variable. Display the model summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>SepalLength</td>   <th>  R-squared:         </th> <td>   0.619</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.614</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   119.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 13 Apr 2020</td> <th>  Prob (F-statistic):</th> <td>1.67e-31</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:59:53</td>     <th>  Log-Likelihood:    </th> <td> -111.73</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   150</td>      <th>  AIC:               </th> <td>   229.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   147</td>      <th>  BIC:               </th> <td>   238.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>               <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>             <td>    5.0060</td> <td>    0.073</td> <td>   68.762</td> <td> 0.000</td> <td>    4.862</td> <td>    5.150</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Species[T.versicolor]</th> <td>    0.9300</td> <td>    0.103</td> <td>    9.033</td> <td> 0.000</td> <td>    0.727</td> <td>    1.133</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Species[T.virginica]</th>  <td>    1.5820</td> <td>    0.103</td> <td>   15.366</td> <td> 0.000</td> <td>    1.379</td> <td>    1.785</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.188</td> <th>  Durbin-Watson:     </th> <td>   2.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.552</td> <th>  Jarque-Bera (JB):  </th> <td>   0.785</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.119</td> <th>  Prob(JB):          </th> <td>   0.675</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.263</td> <th>  Cond. No.          </th> <td>    3.73</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:            SepalLength   R-squared:                       0.619\n",
       "Model:                            OLS   Adj. R-squared:                  0.614\n",
       "Method:                 Least Squares   F-statistic:                     119.3\n",
       "Date:                Mon, 13 Apr 2020   Prob (F-statistic):           1.67e-31\n",
       "Time:                        11:59:53   Log-Likelihood:                -111.73\n",
       "No. Observations:                 150   AIC:                             229.5\n",
       "Df Residuals:                     147   BIC:                             238.5\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=========================================================================================\n",
       "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------\n",
       "Intercept                 5.0060      0.073     68.762      0.000       4.862       5.150\n",
       "Species[T.versicolor]     0.9300      0.103      9.033      0.000       0.727       1.133\n",
       "Species[T.virginica]      1.5820      0.103     15.366      0.000       1.379       1.785\n",
       "==============================================================================\n",
       "Omnibus:                        1.188   Durbin-Watson:                   2.043\n",
       "Prob(Omnibus):                  0.552   Jarque-Bera (JB):                0.785\n",
       "Skew:                           0.119   Prob(JB):                        0.675\n",
       "Kurtosis:                       3.263   Cond. No.                         3.73\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = smf.ols(\"SepalLength ~ Species\", data = df5).fit()\n",
    "mod.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** We would like to test the following null hypothesis at level $\\alpha=0.01$:\n",
    "\n",
    "$$\n",
    "H_0: \\mu_{\\text{setosa}} = \\mu_{\\text{versicolor}} = \\mu_{\\text{virginica}},\n",
    "$$\n",
    "\n",
    "against the alternative that at least one pair of means is different. Here each $\\mu_{\\text{species}}$ represents the population mean petal length for that species.\n",
    "\n",
    "Explain what results in the summary table provide a test of this hypothesis, and state what your conclusion is. Does the test reject $H_0$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The F test is highly significant, F = 119.3, p value < 0.01 => reject null hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)** Determine the estimated mean difference in petal length between virginica and setosa, and give a 95% confidence interval for the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.379, 1.785)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower_bound, upper_bound = 1.379, 1.785\n",
    "lower_bound, upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5819999999999999"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_difference = 6.588-5.006\n",
    "mean_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
